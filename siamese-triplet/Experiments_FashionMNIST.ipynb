{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sx9e_pXlCuti"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMMut8UVCutt"
   },
   "source": [
    "# Experiments\n",
    "We'll go through learning feature embeddings using different loss functions on MNIST dataset. This is just for visualization purposes, thus we'll be using 2-dimensional embeddings which isn't the best choice in practice.\n",
    "\n",
    "For every experiment the same embedding network is used (32 conv 5x5 -> PReLU -> MaxPool 2x2 -> 64 conv 5x5 -> PReLU -> MaxPool 2x2 -> Dense 256 -> PReLU -> Dense 256 -> PReLU -> Dense 2) and we don't do any hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcmGBqXeCutw"
   },
   "source": [
    "# Prepare dataset\n",
    "We'll be working on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3691,
     "status": "ok",
     "timestamp": 1528587668602,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "AQSHPH9P0BNx",
    "outputId": "023d99ab-56d0-4116-e5be-3827035a70dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████▉| 26419200/26421880 [11:33<00:00, 18714.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/29515 [00:01<?, ?it/s]\n",
      " 28%|████████████████████▌                                                     | 8192/29515 [00:01<00:01, 20904.15it/s]\n",
      " 83%|████████████████████████████████████████████████████████████▊            | 24576/29515 [00:01<00:00, 27026.64it/s]\n",
      "32768it [00:01, 20429.49it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/4422102 [00:00<?, ?it/s]\n",
      "  0%|▏                                                                       | 8192/4422102 [00:00<01:47, 41177.00it/s]\n",
      "  0%|▎                                                                      | 16384/4422102 [00:00<01:45, 41632.08it/s]\n",
      "  1%|▍                                                                      | 24576/4422102 [00:01<01:45, 41651.58it/s]\n",
      "  1%|▋                                                                      | 40960/4422102 [00:01<01:30, 48611.24it/s]\n",
      "  1%|▊                                                                      | 49152/4422102 [00:01<01:32, 47332.28it/s]\n",
      "  1%|█                                                                      | 65536/4422102 [00:01<01:20, 53924.80it/s]\n",
      "  2%|█▏                                                                     | 73728/4422102 [00:01<01:28, 49112.22it/s]\n",
      "  2%|█▍                                                                     | 90112/4422102 [00:02<01:17, 56191.06it/s]\n",
      "  2%|█▌                                                                     | 98304/4422102 [00:02<01:23, 51873.49it/s]\n",
      "  2%|█▋                                                                    | 106496/4422102 [00:02<01:31, 47146.35it/s]\n",
      "  3%|█▉                                                                    | 122880/4422102 [00:02<01:18, 54507.56it/s]\n",
      "  3%|██                                                                    | 131072/4422102 [00:02<01:25, 50363.73it/s]\n",
      "  3%|██▏                                                                   | 139264/4422102 [00:02<01:30, 47373.74it/s]\n",
      "  3%|██▎                                                                   | 147456/4422102 [00:03<01:34, 45442.71it/s]\n",
      "  4%|██▍                                                                   | 155648/4422102 [00:03<01:35, 44608.67it/s]\n",
      "  4%|██▌                                                                   | 163840/4422102 [00:03<01:34, 44831.70it/s]\n",
      "  4%|██▋                                                                   | 172032/4422102 [00:03<01:37, 43793.79it/s]\n",
      "  4%|██▊                                                                   | 180224/4422102 [00:04<02:09, 32775.13it/s]\n",
      "  5%|███▏                                                                  | 204800/4422102 [00:04<01:53, 37088.06it/s]\n",
      "  5%|███▌                                                                  | 221184/4422102 [00:04<01:43, 40484.06it/s]\n",
      "  5%|███▋                                                                  | 229376/4422102 [00:05<02:12, 31668.47it/s]\n",
      "  5%|███▊                                                                  | 237568/4422102 [00:05<02:33, 27336.73it/s]\n",
      "  6%|███▉                                                                  | 245760/4422102 [00:05<02:16, 30484.61it/s]\n",
      "  6%|████                                                                  | 253952/4422102 [00:06<02:04, 33514.23it/s]\n",
      "  6%|████▏                                                                 | 262144/4422102 [00:06<02:27, 28185.62it/s]\n",
      "  6%|████▎                                                                 | 270336/4422102 [00:06<02:11, 31507.68it/s]\n",
      "  6%|████▍                                                                 | 278528/4422102 [00:06<02:01, 34007.69it/s]\n",
      "  6%|████▌                                                                 | 286720/4422102 [00:07<01:55, 35900.72it/s]\n",
      "  7%|████▊                                                                 | 303104/4422102 [00:07<01:34, 43463.32it/s]\n",
      "  7%|████▉                                                                 | 311296/4422102 [00:07<01:35, 43186.19it/s]\n",
      "  7%|█████                                                                 | 319488/4422102 [00:07<01:36, 42657.59it/s]\n",
      "  7%|█████▏                                                                | 327680/4422102 [00:07<01:36, 42273.59it/s]\n",
      "  8%|█████▍                                                                | 344064/4422102 [00:08<01:21, 49977.67it/s]\n",
      "  8%|█████▌                                                                | 352256/4422102 [00:08<01:25, 47691.82it/s]\n",
      "  8%|█████▊                                                                | 368640/4422102 [00:08<01:29, 45334.28it/s]\n",
      "  9%|█████▉                                                                | 376832/4422102 [00:08<01:30, 44606.22it/s]\n",
      "  9%|██████▎                                                               | 401408/4422102 [00:09<01:12, 55168.76it/s]\n",
      "  9%|██████▍                                                               | 409600/4422102 [00:09<01:18, 51150.60it/s]\n",
      " 10%|██████▋                                                               | 425984/4422102 [00:09<01:09, 57650.81it/s]\n",
      " 10%|██████▊                                                               | 434176/4422102 [00:09<01:16, 52345.54it/s]\n",
      " 10%|███████▏                                                              | 450560/4422102 [00:09<01:08, 58092.91it/s]\n",
      " 11%|███████▍                                                              | 466944/4422102 [00:10<01:02, 63701.28it/s]\n",
      " 11%|███████▋                                                              | 483328/4422102 [00:10<00:56, 69696.17it/s]\n",
      " 11%|███████▊                                                              | 491520/4422102 [00:10<01:09, 56721.86it/s]\n",
      " 11%|████████                                                              | 507904/4422102 [00:10<01:02, 62714.90it/s]\n",
      " 12%|████████▏                                                             | 516096/4422102 [00:10<01:38, 39667.46it/s]\n",
      " 12%|████████▌                                                             | 540672/4422102 [00:11<01:17, 49794.89it/s]\n",
      " 12%|████████▋                                                             | 548864/4422102 [00:11<01:20, 48066.75it/s]\n",
      " 13%|████████▉                                                             | 565248/4422102 [00:11<01:10, 54830.65it/s]\n",
      " 13%|█████████                                                             | 573440/4422102 [00:11<01:16, 50091.50it/s]\n",
      " 13%|█████████▏                                                            | 581632/4422102 [00:11<01:21, 47152.00it/s]\n",
      " 13%|█████████▎                                                            | 589824/4422102 [00:12<01:23, 45747.97it/s]\n",
      " 14%|█████████▍                                                            | 598016/4422102 [00:12<01:26, 44321.22it/s]\n",
      " 14%|█████████▌                                                            | 606208/4422102 [00:12<01:22, 46369.26it/s]\n",
      " 14%|█████████▊                                                            | 622592/4422102 [00:12<01:13, 51641.28it/s]\n",
      " 14%|█████████▉                                                            | 630784/4422102 [00:12<01:11, 52772.40it/s]\n",
      " 15%|██████████▏                                                           | 647168/4422102 [00:13<01:30, 41539.42it/s]\n",
      " 15%|██████████▋                                                           | 671744/4422102 [00:13<01:13, 50863.13it/s]\n",
      " 15%|██████████▊                                                           | 679936/4422102 [00:13<01:13, 50955.80it/s]\n",
      " 16%|██████████▉                                                           | 688128/4422102 [00:14<01:17, 48311.02it/s]\n",
      "26427392it [11:50, 18714.10it/s]                                                                                       \n",
      " 16%|███████████▍                                                          | 720896/4422102 [00:14<01:14, 49864.03it/s]\n",
      " 17%|███████████▊                                                          | 745472/4422102 [00:14<01:01, 59873.36it/s]\n",
      " 17%|███████████▉                                                          | 753664/4422102 [00:15<01:10, 52277.87it/s]\n",
      " 17%|████████████                                                          | 761856/4422102 [00:15<01:09, 52394.32it/s]\n",
      " 18%|████████████▎                                                         | 778240/4422102 [00:15<01:03, 57102.45it/s]\n",
      " 18%|████████████▍                                                         | 786432/4422102 [00:15<01:07, 53898.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▋                                                         | 802816/4422102 [00:15<00:59, 60563.96it/s]\n",
      " 19%|████████████▉                                                         | 819200/4422102 [00:16<00:54, 66366.93it/s]\n",
      " 19%|█████████████                                                         | 827392/4422102 [00:16<01:04, 55765.03it/s]\n",
      " 19%|█████████████▎                                                        | 843776/4422102 [00:16<00:57, 62254.56it/s]\n",
      " 19%|█████████████▌                                                        | 860160/4422102 [00:16<00:53, 67165.82it/s]\n",
      " 20%|█████████████▉                                                        | 876544/4422102 [00:16<00:49, 72017.64it/s]\n",
      " 20%|██████████████                                                        | 884736/4422102 [00:17<01:25, 41228.09it/s]\n",
      " 21%|██████████████▌                                                       | 917504/4422102 [00:17<01:05, 53421.33it/s]\n",
      " 21%|██████████████▊                                                       | 933888/4422102 [00:17<01:12, 48081.68it/s]\n",
      " 21%|███████████████                                                       | 950272/4422102 [00:18<01:04, 53589.43it/s]\n",
      " 22%|███████████████▏                                                      | 958464/4422102 [00:18<01:44, 33058.65it/s]\n",
      " 22%|███████████████▌                                                      | 983040/4422102 [00:18<01:24, 40465.14it/s]\n",
      " 22%|███████████████▋                                                      | 991232/4422102 [00:18<01:24, 40688.21it/s]\n",
      " 23%|███████████████▊                                                      | 999424/4422102 [00:19<01:22, 41309.33it/s]\n",
      " 23%|███████████████▋                                                     | 1007616/4422102 [00:19<01:11, 47674.01it/s]\n",
      " 23%|███████████████▊                                                     | 1015808/4422102 [00:19<01:03, 53437.21it/s]\n",
      " 23%|███████████████▉                                                     | 1024000/4422102 [00:20<02:07, 26650.49it/s]\n",
      " 24%|████████████████▎                                                    | 1048576/4422102 [00:20<01:40, 33671.64it/s]\n",
      " 24%|████████████████▍                                                    | 1056768/4422102 [00:20<01:33, 35808.21it/s]\n",
      " 24%|████████████████▌                                                    | 1064960/4422102 [00:20<01:20, 41761.57it/s]\n",
      " 24%|████████████████▋                                                    | 1073152/4422102 [00:20<01:19, 42152.16it/s]\n",
      " 25%|█████████████████                                                    | 1089536/4422102 [00:21<01:11, 46444.36it/s]\n",
      " 25%|█████████████████▏                                                   | 1097728/4422102 [00:21<01:36, 34488.38it/s]\n",
      " 25%|█████████████████▍                                                   | 1114112/4422102 [00:21<01:15, 43741.61it/s]\n",
      " 25%|█████████████████▌                                                   | 1122304/4422102 [00:22<01:58, 27941.57it/s]\n",
      " 26%|█████████████████▊                                                   | 1138688/4422102 [00:22<01:36, 33935.62it/s]\n",
      " 26%|█████████████████▉                                                   | 1146880/4422102 [00:22<01:30, 36055.06it/s]\n",
      " 26%|██████████████████                                                   | 1155072/4422102 [00:22<01:44, 31374.91it/s]\n",
      " 26%|██████████████████▏                                                  | 1163264/4422102 [00:23<02:45, 19661.73it/s]\n",
      " 26%|██████████████████▎                                                  | 1171456/4422102 [00:24<03:29, 15505.00it/s]\n",
      " 27%|██████████████████▍                                                  | 1179648/4422102 [00:24<03:12, 16824.66it/s]\n",
      " 27%|██████████████████▌                                                  | 1187840/4422102 [00:25<03:01, 17774.00it/s]\n",
      " 27%|██████████████████▋                                                  | 1196032/4422102 [00:25<02:29, 21577.29it/s]\n",
      " 27%|██████████████████▊                                                  | 1204224/4422102 [00:25<02:07, 25144.82it/s]\n",
      " 27%|██████████████████▉                                                  | 1212416/4422102 [00:25<01:52, 28510.36it/s]\n",
      " 28%|███████████████████                                                  | 1220608/4422102 [00:26<01:41, 31513.68it/s]\n",
      " 28%|███████████████████▏                                                 | 1228800/4422102 [00:26<01:33, 34216.24it/s]\n",
      " 28%|███████████████████▎                                                 | 1236992/4422102 [00:26<01:51, 28632.53it/s]\n",
      " 28%|███████████████████▌                                                 | 1253376/4422102 [00:27<01:35, 33159.27it/s]\n",
      " 29%|███████████████████▋                                                 | 1261568/4422102 [00:27<01:37, 32279.16it/s]\n",
      " 29%|███████████████████▊                                                 | 1269760/4422102 [00:27<01:53, 27837.21it/s]\n",
      " 29%|███████████████████▉                                                 | 1277952/4422102 [00:27<01:32, 33918.03it/s]\n",
      " 29%|████████████████████                                                 | 1286144/4422102 [00:28<02:05, 25047.87it/s]\n",
      " 29%|████████████████████▎                                                | 1302528/4422102 [00:28<01:41, 30628.03it/s]\n",
      " 30%|████████████████████▍                                                | 1310720/4422102 [00:28<01:33, 33235.29it/s]\n",
      " 30%|████████████████████▌                                                | 1318912/4422102 [00:29<01:32, 33471.79it/s]\n",
      " 30%|████████████████████▋                                                | 1327104/4422102 [00:29<01:36, 32094.21it/s]\n",
      " 30%|████████████████████▊                                                | 1335296/4422102 [00:29<01:51, 27758.88it/s]\n",
      " 30%|████████████████████▉                                                | 1343488/4422102 [00:29<01:31, 33752.94it/s]\n",
      " 31%|█████████████████████                                                | 1351680/4422102 [00:30<01:34, 32481.49it/s]\n",
      " 31%|█████████████████████▏                                               | 1359872/4422102 [00:30<01:27, 35012.49it/s]\n",
      " 31%|█████████████████████▎                                               | 1368064/4422102 [00:30<01:22, 36952.44it/s]\n",
      " 31%|█████████████████████▍                                               | 1376256/4422102 [00:30<01:41, 29929.41it/s]\n",
      " 31%|█████████████████████▌                                               | 1384448/4422102 [00:31<01:53, 26734.25it/s]\n",
      " 31%|█████████████████████▋                                               | 1392640/4422102 [00:31<02:33, 19782.14it/s]\n",
      " 32%|█████████████████████▉                                               | 1409024/4422102 [00:32<02:08, 23477.68it/s]\n",
      " 32%|██████████████████████▏                                              | 1425408/4422102 [00:32<01:39, 29993.50it/s]\n",
      " 32%|██████████████████████▎                                              | 1433600/4422102 [00:32<01:30, 32935.94it/s]\n",
      " 33%|██████████████████████▍                                              | 1441792/4422102 [00:33<01:45, 28144.00it/s]\n",
      " 33%|██████████████████████▌                                              | 1449984/4422102 [00:33<01:35, 31219.54it/s]\n",
      " 33%|██████████████████████▊                                              | 1458176/4422102 [00:33<01:27, 33744.91it/s]\n",
      " 33%|██████████████████████▉                                              | 1466368/4422102 [00:33<01:42, 28819.03it/s]\n",
      " 33%|███████████████████████                                              | 1474560/4422102 [00:34<01:32, 31719.43it/s]\n",
      " 34%|███████████████████████▏                                             | 1482752/4422102 [00:34<01:46, 27534.63it/s]\n",
      " 34%|███████████████████████▍                                             | 1499136/4422102 [00:34<01:24, 34531.37it/s]\n",
      " 34%|███████████████████████▌                                             | 1507328/4422102 [00:34<01:19, 36719.92it/s]\n",
      " 34%|███████████████████████▋                                             | 1515520/4422102 [00:35<01:37, 29774.20it/s]\n",
      " 35%|███████████████████████▉                                             | 1531904/4422102 [00:35<01:18, 36839.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████                                             | 1540096/4422102 [00:35<01:15, 38061.51it/s]\n",
      " 35%|████████████████████████▏                                            | 1548288/4422102 [00:35<01:33, 30730.86it/s]\n",
      " 35%|████████████████████████▎                                            | 1556480/4422102 [00:36<01:25, 33494.76it/s]\n",
      " 35%|████████████████████████▍                                            | 1564672/4422102 [00:36<01:19, 35893.15it/s]\n",
      " 36%|████████████████████████▌                                            | 1572864/4422102 [00:36<01:36, 29495.74it/s]\n",
      " 36%|████████████████████████▋                                            | 1581056/4422102 [00:36<01:28, 32216.12it/s]\n",
      " 36%|████████████████████████▉                                            | 1597440/4422102 [00:37<01:11, 39382.17it/s]\n",
      " 36%|█████████████████████████                                            | 1605632/4422102 [00:37<01:10, 40211.25it/s]\n",
      " 36%|█████████████████████████▏                                           | 1613824/4422102 [00:37<01:08, 41034.51it/s]\n",
      " 37%|█████████████████████████▎                                           | 1622016/4422102 [00:37<01:07, 41229.18it/s]\n",
      " 37%|█████████████████████████▍                                           | 1630208/4422102 [00:37<01:08, 40776.88it/s]\n",
      " 37%|█████████████████████████▋                                           | 1646592/4422102 [00:38<00:57, 48432.07it/s]\n",
      " 37%|█████████████████████████▊                                           | 1654784/4422102 [00:38<00:59, 46136.58it/s]\n",
      " 38%|██████████████████████████                                           | 1671168/4422102 [00:38<00:51, 53610.08it/s]\n",
      " 38%|██████████████████████████▎                                          | 1687552/4422102 [00:38<00:45, 59803.95it/s]\n",
      " 39%|██████████████████████████▌                                          | 1703936/4422102 [00:38<00:41, 65610.38it/s]\n",
      " 39%|██████████████████████████▊                                          | 1720320/4422102 [00:39<00:38, 69606.16it/s]\n",
      " 39%|██████████████████████████▉                                          | 1728512/4422102 [00:39<00:46, 57812.15it/s]\n",
      " 39%|███████████████████████████                                          | 1736704/4422102 [00:39<00:50, 52750.28it/s]\n",
      " 39%|███████████████████████████▏                                         | 1744896/4422102 [00:39<00:54, 49427.22it/s]\n",
      " 40%|███████████████████████████▍                                         | 1761280/4422102 [00:39<00:47, 56113.87it/s]\n",
      " 40%|███████████████████████████▌                                         | 1769472/4422102 [00:40<01:11, 37280.51it/s]\n",
      " 40%|███████████████████████████▊                                         | 1785856/4422102 [00:40<00:58, 44750.45it/s]\n",
      " 41%|███████████████████████████▉                                         | 1794048/4422102 [00:40<00:53, 49006.23it/s]\n",
      " 41%|████████████████████████████                                         | 1802240/4422102 [00:40<01:02, 41998.34it/s]\n",
      " 41%|████████████████████████████▏                                        | 1810432/4422102 [00:41<01:01, 42570.92it/s]\n",
      " 41%|████████████████████████████▍                                        | 1818624/4422102 [00:41<01:01, 42067.59it/s]\n",
      " 41%|████████████████████████████▌                                        | 1826816/4422102 [00:41<01:02, 41732.66it/s]\n",
      " 41%|████████████████████████████▋                                        | 1835008/4422102 [00:41<01:01, 42131.52it/s]\n",
      " 42%|████████████████████████████▊                                        | 1843200/4422102 [00:41<00:56, 45989.11it/s]\n",
      " 42%|████████████████████████████▉                                        | 1851392/4422102 [00:42<01:34, 27062.91it/s]\n",
      " 42%|█████████████████████████████▏                                       | 1867776/4422102 [00:42<01:15, 33800.74it/s]\n",
      " 42%|█████████████████████████████▎                                       | 1875968/4422102 [00:43<01:46, 23962.80it/s]\n",
      " 43%|█████████████████████████████▌                                       | 1892352/4422102 [00:43<01:41, 25035.54it/s]\n",
      " 43%|█████████████████████████████▋                                       | 1900544/4422102 [00:43<01:28, 28337.96it/s]\n",
      " 43%|█████████████████████████████▊                                       | 1908736/4422102 [00:44<01:38, 25572.49it/s]\n",
      " 43%|█████████████████████████████▉                                       | 1916928/4422102 [00:44<01:26, 28817.39it/s]\n",
      " 44%|██████████████████████████████                                       | 1925120/4422102 [00:44<01:18, 31884.81it/s]\n",
      " 44%|██████████████████████████████▏                                      | 1933312/4422102 [00:45<01:48, 22892.36it/s]\n",
      " 44%|██████████████████████████████▍                                      | 1949696/4422102 [00:45<01:24, 29361.05it/s]\n",
      " 44%|██████████████████████████████▌                                      | 1957888/4422102 [00:45<01:34, 26148.37it/s]\n",
      " 45%|██████████████████████████████▊                                      | 1974272/4422102 [00:46<01:14, 33021.86it/s]\n",
      " 45%|██████████████████████████████▉                                      | 1982464/4422102 [00:46<01:10, 34842.04it/s]\n",
      " 45%|███████████████████████████████                                      | 1990656/4422102 [00:46<01:06, 36471.32it/s]\n",
      " 45%|███████████████████████████████▏                                     | 1998848/4422102 [00:46<01:03, 38305.89it/s]\n",
      " 45%|███████████████████████████████▎                                     | 2007040/4422102 [00:46<01:01, 39377.66it/s]\n",
      " 46%|███████████████████████████████▍                                     | 2015232/4422102 [00:47<01:17, 30902.22it/s]\n",
      " 46%|███████████████████████████████▌                                     | 2023424/4422102 [00:47<01:10, 33962.84it/s]\n",
      " 46%|███████████████████████████████▋                                     | 2031616/4422102 [00:47<01:06, 35792.62it/s]\n",
      " 46%|███████████████████████████████▊                                     | 2039808/4422102 [00:47<01:03, 37570.30it/s]\n",
      " 46%|███████████████████████████████▉                                     | 2048000/4422102 [00:48<01:18, 30219.69it/s]\n",
      " 47%|████████████████████████████████▏                                    | 2064384/4422102 [00:48<01:11, 32958.57it/s]\n",
      " 47%|████████████████████████████████▎                                    | 2072576/4422102 [00:49<01:23, 28254.18it/s]\n",
      " 47%|████████████████████████████████▍                                    | 2080768/4422102 [00:49<01:14, 31321.76it/s]\n",
      " 47%|████████████████████████████████▌                                    | 2088960/4422102 [00:49<01:31, 25397.87it/s]\n",
      " 47%|████████████████████████████████▋                                    | 2097152/4422102 [00:49<01:14, 31290.87it/s]\n",
      " 48%|████████████████████████████████▊                                    | 2105344/4422102 [00:50<01:08, 33964.78it/s]\n",
      " 48%|████████████████████████████████▉                                    | 2113536/4422102 [00:50<01:20, 28653.78it/s]\n",
      " 48%|█████████████████████████████████                                    | 2121728/4422102 [00:51<02:02, 18784.95it/s]\n",
      " 48%|█████████████████████████████████▏                                   | 2129920/4422102 [00:51<01:52, 20346.25it/s]\n",
      " 48%|█████████████████████████████████▎                                   | 2138112/4422102 [00:52<02:06, 18026.34it/s]\n",
      " 49%|█████████████████████████████████▍                                   | 2146304/4422102 [00:52<01:45, 21656.99it/s]\n",
      " 49%|█████████████████████████████████▌                                   | 2154496/4422102 [00:52<01:45, 21578.71it/s]\n",
      " 49%|█████████████████████████████████▋                                   | 2162688/4422102 [00:52<01:29, 25146.12it/s]\n",
      " 49%|█████████████████████████████████▊                                   | 2170880/4422102 [00:53<01:19, 28437.07it/s]\n",
      " 49%|██████████████████████████████████                                   | 2179072/4422102 [00:53<01:11, 31557.48it/s]\n",
      " 49%|██████████████████████████████████▏                                  | 2187264/4422102 [00:53<01:05, 33886.99it/s]\n",
      " 50%|██████████████████████████████████▍                                  | 2203648/4422102 [00:53<00:53, 41331.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████▌                                  | 2211840/4422102 [00:54<01:08, 32153.50it/s]\n",
      " 50%|██████████████████████████████████▊                                  | 2228224/4422102 [00:54<01:10, 31223.42it/s]\n",
      " 51%|██████████████████████████████████▉                                  | 2236416/4422102 [00:54<01:04, 33908.71it/s]\n",
      " 51%|███████████████████████████████████                                  | 2244608/4422102 [00:54<00:59, 36421.70it/s]\n",
      " 51%|███████████████████████████████████▏                                 | 2252800/4422102 [00:55<01:01, 35538.58it/s]\n",
      " 51%|███████████████████████████████████▎                                 | 2260992/4422102 [00:55<00:57, 37316.81it/s]\n",
      " 51%|███████████████████████████████████▍                                 | 2269184/4422102 [00:55<01:08, 31555.81it/s]\n",
      " 51%|███████████████████████████████████▌                                 | 2277376/4422102 [00:55<01:03, 34025.41it/s]\n",
      " 52%|███████████████████████████████████▋                                 | 2285568/4422102 [00:56<00:59, 35840.98it/s]\n",
      " 52%|███████████████████████████████████▊                                 | 2293760/4422102 [00:56<00:52, 40770.41it/s]\n",
      " 52%|████████████████████████████████████                                 | 2310144/4422102 [00:56<00:45, 45978.28it/s]\n",
      " 52%|████████████████████████████████████▏                                | 2318336/4422102 [00:56<01:02, 33614.50it/s]\n",
      " 53%|████████████████████████████████████▍                                | 2334720/4422102 [00:57<00:50, 40931.92it/s]\n",
      " 53%|████████████████████████████████████▌                                | 2342912/4422102 [00:57<01:05, 31625.37it/s]\n",
      " 53%|████████████████████████████████████▋                                | 2351104/4422102 [00:57<01:00, 34369.11it/s]\n",
      " 54%|████████████████████████████████████▉                                | 2367488/4422102 [00:57<00:49, 41836.06it/s]\n",
      " 54%|█████████████████████████████████████                                | 2375680/4422102 [00:58<00:48, 42205.24it/s]\n",
      " 54%|█████████████████████████████████████▏                               | 2383872/4422102 [00:58<00:48, 41817.01it/s]\n",
      " 54%|█████████████████████████████████████▎                               | 2392064/4422102 [00:58<00:48, 41992.22it/s]\n",
      " 54%|█████████████████████████████████████▌                               | 2408448/4422102 [00:58<00:40, 49179.20it/s]\n",
      " 55%|█████████████████████████████████████▋                               | 2416640/4422102 [00:58<00:43, 46378.34it/s]\n",
      " 55%|█████████████████████████████████████▊                               | 2424832/4422102 [00:59<00:58, 34330.84it/s]\n",
      " 55%|██████████████████████████████████████▏                              | 2449408/4422102 [00:59<00:44, 43881.35it/s]\n",
      " 56%|██████████████████████████████████████▎                              | 2457600/4422102 [00:59<01:00, 32670.75it/s]\n",
      " 56%|██████████████████████████████████████▍                              | 2465792/4422102 [01:00<00:55, 35089.38it/s]\n",
      " 56%|██████████████████████████████████████▌                              | 2473984/4422102 [01:00<00:53, 36660.73it/s]\n",
      " 56%|██████████████████████████████████████▋                              | 2482176/4422102 [01:00<00:50, 38379.23it/s]\n",
      " 56%|██████████████████████████████████████▊                              | 2490368/4422102 [01:00<01:02, 30730.29it/s]\n",
      " 57%|███████████████████████████████████████                              | 2506752/4422102 [01:01<00:52, 36819.74it/s]\n",
      " 57%|███████████████████████████████████████▏                             | 2514944/4422102 [01:01<00:50, 37965.53it/s]\n",
      " 57%|███████████████████████████████████████▎                             | 2523136/4422102 [01:01<00:45, 41781.92it/s]\n",
      " 57%|███████████████████████████████████████▍                             | 2531328/4422102 [01:01<00:45, 41967.04it/s]\n",
      " 57%|███████████████████████████████████████▋                             | 2539520/4422102 [01:01<00:45, 41652.90it/s]\n",
      " 58%|███████████████████████████████████████▊                             | 2547712/4422102 [01:02<00:47, 39565.15it/s]\n",
      " 58%|████████████████████████████████████████                             | 2564096/4422102 [01:02<00:39, 47153.61it/s]\n",
      " 58%|████████████████████████████████████████▏                            | 2572288/4422102 [01:02<01:02, 29404.43it/s]\n",
      " 59%|████████████████████████████████████████▍                            | 2588672/4422102 [01:03<00:52, 34893.21it/s]\n",
      " 59%|████████████████████████████████████████▌                            | 2596864/4422102 [01:03<00:49, 36596.22it/s]\n",
      " 59%|████████████████████████████████████████▋                            | 2605056/4422102 [01:03<00:56, 32031.73it/s]\n",
      " 59%|████████████████████████████████████████▊                            | 2613248/4422102 [01:03<00:52, 34572.60it/s]\n",
      " 59%|████████████████████████████████████████▉                            | 2621440/4422102 [01:04<01:02, 28769.55it/s]\n",
      " 59%|█████████████████████████████████████████                            | 2629632/4422102 [01:04<00:56, 31943.71it/s]\n",
      " 60%|█████████████████████████████████████████▏                           | 2637824/4422102 [01:04<00:51, 34631.72it/s]\n",
      " 60%|█████████████████████████████████████████▎                           | 2646016/4422102 [01:04<00:49, 36144.41it/s]\n",
      " 60%|█████████████████████████████████████████▍                           | 2654208/4422102 [01:04<00:43, 40822.20it/s]\n",
      " 60%|█████████████████████████████████████████▌                           | 2662400/4422102 [01:05<00:42, 41477.93it/s]\n",
      " 60%|█████████████████████████████████████████▋                           | 2670592/4422102 [01:05<00:42, 40844.29it/s]\n",
      " 61%|█████████████████████████████████████████▊                           | 2678784/4422102 [01:05<00:55, 31628.24it/s]\n",
      " 61%|█████████████████████████████████████████▉                           | 2686976/4422102 [01:05<00:50, 34680.24it/s]\n",
      " 61%|██████████████████████████████████████████                           | 2695168/4422102 [01:06<01:08, 25334.28it/s]\n",
      " 61%|██████████████████████████████████████████▎                          | 2711552/4422102 [01:06<00:59, 28755.88it/s]\n",
      " 62%|██████████████████████████████████████████▍                          | 2719744/4422102 [01:07<01:05, 25809.96it/s]\n",
      " 62%|██████████████████████████████████████████▌                          | 2727936/4422102 [01:07<01:10, 23872.14it/s]\n",
      " 62%|██████████████████████████████████████████▋                          | 2736128/4422102 [01:07<01:13, 22870.02it/s]\n",
      " 62%|██████████████████████████████████████████▊                          | 2744320/4422102 [01:08<01:03, 26390.73it/s]\n",
      " 62%|██████████████████████████████████████████▉                          | 2752512/4422102 [01:08<01:08, 24528.17it/s]\n",
      " 63%|███████████████████████████████████████████▏                         | 2768896/4422102 [01:08<00:53, 31053.34it/s]\n",
      " 63%|███████████████████████████████████████████▎                         | 2777088/4422102 [01:08<00:48, 33712.21it/s]\n",
      " 63%|███████████████████████████████████████████▍                         | 2785280/4422102 [01:09<01:09, 23583.97it/s]\n",
      " 63%|███████████████████████████████████████████▋                         | 2801664/4422102 [01:09<00:54, 29989.26it/s]\n",
      " 64%|███████████████████████████████████████████▊                         | 2809856/4422102 [01:09<00:49, 32441.73it/s]\n",
      " 64%|███████████████████████████████████████████▉                         | 2818048/4422102 [01:10<00:46, 34648.24it/s]\n",
      " 64%|████████████████████████████████████████████                         | 2826240/4422102 [01:10<00:55, 28686.72it/s]\n",
      " 64%|████████████████████████████████████████████▎                        | 2842624/4422102 [01:11<00:55, 28607.42it/s]\n",
      " 64%|████████████████████████████████████████████▍                        | 2850816/4422102 [01:11<00:49, 31449.21it/s]\n",
      " 65%|████████████████████████████████████████████▌                        | 2859008/4422102 [01:11<00:49, 31461.65it/s]\n",
      " 65%|████████████████████████████████████████████▋                        | 2867200/4422102 [01:11<00:45, 34101.87it/s]\n",
      " 65%|████████████████████████████████████████████▊                        | 2875392/4422102 [01:12<01:05, 23775.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████▉                        | 2883584/4422102 [01:12<00:56, 27196.36it/s]\n",
      " 65%|█████████████████████████████████████████████                        | 2891776/4422102 [01:13<01:19, 19257.04it/s]\n",
      " 66%|█████████████████████████████████████████████▍                       | 2908160/4422102 [01:13<01:07, 22307.24it/s]\n",
      " 66%|█████████████████████████████████████████████▌                       | 2916352/4422102 [01:14<01:08, 21892.71it/s]\n",
      " 66%|█████████████████████████████████████████████▋                       | 2924544/4422102 [01:14<01:09, 21560.77it/s]\n",
      " 66%|█████████████████████████████████████████████▊                       | 2932736/4422102 [01:15<01:20, 18576.12it/s]\n",
      " 67%|█████████████████████████████████████████████▉                       | 2940928/4422102 [01:15<01:06, 22159.38it/s]\n",
      " 67%|██████████████████████████████████████████████                       | 2949120/4422102 [01:15<01:07, 21743.08it/s]\n",
      " 67%|██████████████████████████████████████████████▏                      | 2957312/4422102 [01:16<01:08, 21460.95it/s]\n",
      " 67%|██████████████████████████████████████████████▎                      | 2965504/4422102 [01:16<00:58, 25034.08it/s]\n",
      " 67%|██████████████████████████████████████████████▍                      | 2973696/4422102 [01:16<01:01, 23605.51it/s]\n",
      " 67%|██████████████████████████████████████████████▌                      | 2981888/4422102 [01:17<01:03, 22698.24it/s]\n",
      " 68%|██████████████████████████████████████████████▋                      | 2990080/4422102 [01:17<00:54, 26200.27it/s]\n",
      " 68%|██████████████████████████████████████████████▊                      | 2998272/4422102 [01:17<00:48, 29575.14it/s]\n",
      " 68%|██████████████████████████████████████████████▉                      | 3006464/4422102 [01:17<00:53, 26357.58it/s]\n",
      " 68%|███████████████████████████████████████████████                      | 3014656/4422102 [01:18<00:47, 29628.94it/s]\n",
      " 68%|███████████████████████████████████████████████▏                     | 3022848/4422102 [01:18<00:43, 32306.30it/s]\n",
      " 69%|███████████████████████████████████████████████▎                     | 3031040/4422102 [01:18<00:50, 27714.84it/s]\n",
      " 69%|███████████████████████████████████████████████▍                     | 3039232/4422102 [01:19<00:55, 25092.11it/s]\n",
      " 69%|███████████████████████████████████████████████▌                     | 3047424/4422102 [01:19<01:17, 17737.09it/s]\n",
      " 69%|███████████████████████████████████████████████▋                     | 3055616/4422102 [01:21<01:56, 11730.43it/s]\n",
      " 69%|███████████████████████████████████████████████▊                     | 3063808/4422102 [01:21<01:55, 11739.95it/s]\n",
      " 69%|███████████████████████████████████████████████▉                     | 3072000/4422102 [01:21<01:30, 14980.12it/s]\n",
      " 70%|████████████████████████████████████████████████                     | 3080192/4422102 [01:22<01:41, 13265.45it/s]\n",
      " 70%|████████████████████████████████████████████████▏                    | 3088384/4422102 [01:23<01:41, 13152.50it/s]\n",
      " 70%|████████████████████████████████████████████████▎                    | 3096576/4422102 [01:23<01:19, 16598.43it/s]\n",
      " 70%|████████████████████████████████████████████████▍                    | 3104768/4422102 [01:24<01:42, 12811.29it/s]\n",
      " 70%|████████████████████████████████████████████████▌                    | 3112960/4422102 [01:25<01:37, 13397.56it/s]\n",
      " 71%|████████████████████████████████████████████████▋                    | 3121152/4422102 [01:26<01:54, 11355.54it/s]\n",
      " 71%|████████████████████████████████████████████████▊                    | 3129344/4422102 [01:26<01:43, 12550.35it/s]\n",
      " 71%|████████████████████████████████████████████████▉                    | 3137536/4422102 [01:26<01:30, 14252.18it/s]\n",
      " 71%|█████████████████████████████████████████████████                    | 3145728/4422102 [01:27<01:21, 15680.97it/s]\n",
      " 71%|█████████████████████████████████████████████████▏                   | 3153920/4422102 [01:27<01:14, 16949.37it/s]\n",
      " 72%|█████████████████████████████████████████████████▎                   | 3162112/4422102 [01:27<01:01, 20614.19it/s]\n",
      " 72%|█████████████████████████████████████████████████▌                   | 3178496/4422102 [01:28<00:46, 26580.70it/s]\n",
      " 72%|█████████████████████████████████████████████████▋                   | 3186688/4422102 [01:28<00:41, 30033.11it/s]\n",
      " 72%|█████████████████████████████████████████████████▊                   | 3194880/4422102 [01:28<00:37, 32641.63it/s]\n",
      " 72%|█████████████████████████████████████████████████▉                   | 3203072/4422102 [01:29<00:52, 23280.50it/s]\n",
      " 73%|██████████████████████████████████████████████████                   | 3211264/4422102 [01:29<00:45, 26832.51it/s]\n",
      " 73%|██████████████████████████████████████████████████▏                  | 3219456/4422102 [01:29<00:48, 24623.96it/s]\n",
      " 73%|██████████████████████████████████████████████████▎                  | 3227648/4422102 [01:29<00:42, 28421.40it/s]\n",
      " 73%|██████████████████████████████████████████████████▍                  | 3235840/4422102 [01:30<00:37, 31234.89it/s]\n",
      " 73%|██████████████████████████████████████████████████▌                  | 3244032/4422102 [01:30<00:37, 31144.48it/s]\n",
      " 74%|██████████████████████████████████████████████████▋                  | 3252224/4422102 [01:30<00:39, 29809.56it/s]\n",
      " 74%|██████████████████████████████████████████████████▊                  | 3260416/4422102 [01:30<00:36, 31809.12it/s]\n",
      " 74%|███████████████████████████████████████████████████                  | 3268608/4422102 [01:31<00:50, 23057.43it/s]\n",
      " 74%|███████████████████████████████████████████████████▎                 | 3284992/4422102 [01:32<00:48, 23441.26it/s]\n",
      " 74%|███████████████████████████████████████████████████▍                 | 3293184/4422102 [01:32<01:05, 17108.49it/s]\n",
      " 75%|███████████████████████████████████████████████████▋                 | 3309568/4422102 [01:33<00:57, 19352.90it/s]\n",
      " 75%|███████████████████████████████████████████████████▊                 | 3317760/4422102 [01:33<00:47, 23135.66it/s]\n",
      " 75%|███████████████████████████████████████████████████▉                 | 3325952/4422102 [01:33<00:40, 26887.37it/s]\n",
      " 75%|████████████████████████████████████████████████████                 | 3334144/4422102 [01:34<00:36, 29973.65it/s]\n",
      " 76%|████████████████████████████████████████████████████▏                | 3342336/4422102 [01:34<00:41, 26219.70it/s]\n",
      " 76%|████████████████████████████████████████████████████▎                | 3350528/4422102 [01:34<00:36, 29709.56it/s]\n",
      " 76%|████████████████████████████████████████████████████▍                | 3358720/4422102 [01:34<00:32, 32257.98it/s]\n",
      " 76%|████████████████████████████████████████████████████▌                | 3366912/4422102 [01:35<00:30, 34449.21it/s]\n",
      " 76%|████████████████████████████████████████████████████▋                | 3375104/4422102 [01:35<00:29, 36038.42it/s]\n",
      " 77%|████████████████████████████████████████████████████▊                | 3383296/4422102 [01:35<00:27, 37835.27it/s]\n",
      " 77%|████████████████████████████████████████████████████▉                | 3391488/4422102 [01:35<00:33, 30508.27it/s]\n",
      " 77%|█████████████████████████████████████████████████████▏               | 3407872/4422102 [01:36<00:30, 33144.60it/s]\n",
      " 77%|█████████████████████████████████████████████████████▎               | 3416064/4422102 [01:36<00:28, 34934.26it/s]\n",
      " 77%|█████████████████████████████████████████████████████▍               | 3424256/4422102 [01:36<00:26, 37037.88it/s]\n",
      " 78%|█████████████████████████████████████████████████████▋               | 3440640/4422102 [01:36<00:23, 42173.13it/s]\n",
      " 78%|█████████████████████████████████████████████████████▊               | 3448832/4422102 [01:37<00:23, 41667.24it/s]\n",
      " 78%|█████████████████████████████████████████████████████▉               | 3457024/4422102 [01:37<00:22, 42084.95it/s]\n",
      " 78%|██████████████████████████████████████████████████████               | 3465216/4422102 [01:37<00:29, 32015.62it/s]\n",
      " 79%|██████████████████████████████████████████████████████▏              | 3473408/4422102 [01:37<00:25, 37822.99it/s]\n",
      " 79%|██████████████████████████████████████████████████████▎              | 3481600/4422102 [01:38<00:26, 35754.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████▍              | 3489792/4422102 [01:38<00:25, 37166.35it/s]\n",
      " 79%|██████████████████████████████████████████████████████▌              | 3497984/4422102 [01:38<00:28, 32355.01it/s]\n",
      " 79%|██████████████████████████████████████████████████████▋              | 3506176/4422102 [01:38<00:28, 32090.83it/s]\n",
      " 79%|██████████████████████████████████████████████████████▊              | 3514368/4422102 [01:39<00:26, 34605.33it/s]\n",
      " 80%|██████████████████████████████████████████████████████▉              | 3522560/4422102 [01:39<00:24, 36289.44it/s]\n",
      " 80%|███████████████████████████████████████████████████████              | 3530752/4422102 [01:39<00:28, 31657.71it/s]\n",
      " 80%|███████████████████████████████████████████████████████▏             | 3538944/4422102 [01:40<00:34, 25893.20it/s]\n",
      " 80%|███████████████████████████████████████████████████████▎             | 3547136/4422102 [01:40<00:29, 29418.17it/s]\n",
      " 80%|███████████████████████████████████████████████████████▍             | 3555328/4422102 [01:40<00:26, 32130.50it/s]\n",
      " 81%|███████████████████████████████████████████████████████▌             | 3563520/4422102 [01:40<00:24, 34535.72it/s]\n",
      " 81%|███████████████████████████████████████████████████████▋             | 3571712/4422102 [01:40<00:23, 36235.74it/s]\n",
      " 81%|███████████████████████████████████████████████████████▊             | 3579904/4422102 [01:41<00:22, 37464.43it/s]\n",
      " 81%|███████████████████████████████████████████████████████▉             | 3588096/4422102 [01:41<00:21, 38893.64it/s]\n",
      " 81%|████████████████████████████████████████████████████████             | 3596288/4422102 [01:41<00:20, 39485.18it/s]\n",
      " 82%|████████████████████████████████████████████████████████▏            | 3604480/4422102 [01:41<00:25, 31466.69it/s]\n",
      " 82%|████████████████████████████████████████████████████████▍            | 3620864/4422102 [01:42<00:25, 31235.52it/s]\n",
      " 82%|████████████████████████████████████████████████████████▋            | 3629056/4422102 [01:42<00:23, 34045.94it/s]\n",
      " 82%|████████████████████████████████████████████████████████▊            | 3637248/4422102 [01:42<00:21, 35728.70it/s]\n",
      " 82%|████████████████████████████████████████████████████████▉            | 3645440/4422102 [01:43<00:26, 29575.68it/s]\n",
      " 83%|█████████████████████████████████████████████████████████            | 3653632/4422102 [01:43<00:23, 32312.98it/s]\n",
      " 83%|█████████████████████████████████████████████████████████▏           | 3661824/4422102 [01:43<00:21, 34934.64it/s]\n",
      " 83%|█████████████████████████████████████████████████████████▎           | 3670016/4422102 [01:43<00:21, 35746.97it/s]\n",
      " 83%|█████████████████████████████████████████████████████████▍           | 3678208/4422102 [01:43<00:19, 38033.58it/s]\n",
      " 83%|█████████████████████████████████████████████████████████▌           | 3686400/4422102 [01:44<00:18, 38860.70it/s]\n",
      " 84%|█████████████████████████████████████████████████████████▋           | 3694592/4422102 [01:44<00:23, 30758.22it/s]\n",
      " 84%|█████████████████████████████████████████████████████████▊           | 3702784/4422102 [01:44<00:21, 33647.49it/s]\n",
      " 84%|█████████████████████████████████████████████████████████▉           | 3710976/4422102 [01:45<00:25, 27810.57it/s]\n",
      " 84%|██████████████████████████████████████████████████████████▏          | 3727360/4422102 [01:45<00:19, 35127.22it/s]\n",
      " 84%|██████████████████████████████████████████████████████████▎          | 3735552/4422102 [01:45<00:18, 37067.77it/s]\n",
      " 85%|██████████████████████████████████████████████████████████▍          | 3743744/4422102 [01:45<00:22, 29699.08it/s]\n",
      " 85%|██████████████████████████████████████████████████████████▋          | 3760128/4422102 [01:46<00:17, 36894.02it/s]\n",
      " 85%|██████████████████████████████████████████████████████████▊          | 3768320/4422102 [01:46<00:18, 35087.72it/s]\n",
      " 85%|██████████████████████████████████████████████████████████▉          | 3776512/4422102 [01:46<00:19, 32337.47it/s]\n",
      " 86%|███████████████████████████████████████████████████████████          | 3784704/4422102 [01:46<00:19, 33530.50it/s]\n",
      " 86%|███████████████████████████████████████████████████████████▏         | 3792896/4422102 [01:47<00:22, 28067.98it/s]\n",
      " 86%|███████████████████████████████████████████████████████████▎         | 3801088/4422102 [01:47<00:24, 25383.32it/s]\n",
      " 86%|███████████████████████████████████████████████████████████▍         | 3809280/4422102 [01:47<00:21, 29067.81it/s]\n",
      " 86%|███████████████████████████████████████████████████████████▌         | 3817472/4422102 [01:48<00:19, 31596.59it/s]\n",
      " 87%|███████████████████████████████████████████████████████████▋         | 3825664/4422102 [01:48<00:17, 34020.91it/s]\n",
      " 87%|███████████████████████████████████████████████████████████▊         | 3833856/4422102 [01:48<00:16, 36314.40it/s]\n",
      " 87%|███████████████████████████████████████████████████████████▉         | 3842048/4422102 [01:48<00:15, 38020.63it/s]\n",
      " 87%|████████████████████████████████████████████████████████████         | 3850240/4422102 [01:48<00:14, 38496.79it/s]\n",
      " 87%|████████████████████████████████████████████████████████████▏        | 3858432/4422102 [01:49<00:14, 39305.99it/s]\n",
      " 87%|████████████████████████████████████████████████████████████▎        | 3866624/4422102 [01:49<00:13, 40672.46it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▍        | 3874816/4422102 [01:49<00:13, 40751.84it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▌        | 3883008/4422102 [01:49<00:13, 40617.74it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▋        | 3891200/4422102 [01:49<00:12, 41329.86it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▉        | 3907584/4422102 [01:50<00:10, 49057.51it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████        | 3915776/4422102 [01:50<00:11, 45854.73it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████▏       | 3923968/4422102 [01:50<00:11, 44989.54it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████▍       | 3940352/4422102 [01:50<00:09, 52521.01it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████▌       | 3948544/4422102 [01:51<00:13, 35635.41it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████▋       | 3956736/4422102 [01:51<00:15, 29578.82it/s]\n",
      " 90%|██████████████████████████████████████████████████████████████▏      | 3989504/4422102 [01:51<00:11, 36595.65it/s]\n",
      " 90%|██████████████████████████████████████████████████████████████▍      | 3997696/4422102 [01:52<00:11, 38463.55it/s]\n",
      " 91%|██████████████████████████████████████████████████████████████▋      | 4014080/4422102 [01:52<00:08, 46125.72it/s]\n",
      " 91%|██████████████████████████████████████████████████████████████▊      | 4022272/4422102 [01:52<00:14, 27055.71it/s]\n",
      " 91%|██████████████████████████████████████████████████████████████▉      | 4030464/4422102 [01:53<00:15, 24943.30it/s]\n",
      " 91%|███████████████████████████████████████████████████████████████      | 4038656/4422102 [01:53<00:13, 28172.61it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████▎     | 4055040/4422102 [01:53<00:11, 33156.80it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████▍     | 4063232/4422102 [01:53<00:10, 35480.01it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████▌     | 4071424/4422102 [01:54<00:09, 36888.84it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████▋     | 4079616/4422102 [01:54<00:08, 38553.94it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████▊     | 4087808/4422102 [01:54<00:08, 39310.86it/s]\n",
      " 93%|███████████████████████████████████████████████████████████████▉     | 4096000/4422102 [01:54<00:10, 30804.30it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████     | 4104192/4422102 [01:55<00:09, 33707.39it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████▏    | 4112384/4422102 [01:55<00:08, 35593.41it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████▎    | 4120576/4422102 [01:55<00:08, 37015.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████▍    | 4128768/4422102 [01:55<00:07, 38535.94it/s]\n",
      " 94%|████████████████████████████████████████████████████████████████▋    | 4145152/4422102 [01:55<00:05, 46198.44it/s]\n",
      " 94%|████████████████████████████████████████████████████████████████▊    | 4153344/4422102 [01:56<00:06, 44471.13it/s]\n",
      " 94%|████████████████████████████████████████████████████████████████▉    | 4161536/4422102 [01:56<00:06, 43348.75it/s]\n",
      " 94%|█████████████████████████████████████████████████████████████████    | 4169728/4422102 [01:57<00:11, 22194.36it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████▎   | 4186112/4422102 [01:57<00:09, 25883.73it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████▍   | 4194304/4422102 [01:57<00:07, 29108.29it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████▌   | 4202496/4422102 [01:58<00:08, 26083.79it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████▋   | 4210688/4422102 [01:58<00:07, 29180.75it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████▊   | 4218880/4422102 [01:58<00:06, 32309.98it/s]\n",
      " 96%|█████████████████████████████████████████████████████████████████▉   | 4227072/4422102 [01:58<00:05, 34257.91it/s]\n",
      " 96%|██████████████████████████████████████████████████████████████████   | 4235264/4422102 [01:58<00:05, 36111.05it/s]\n",
      " 96%|██████████████████████████████████████████████████████████████████▎  | 4251648/4422102 [01:59<00:04, 37547.01it/s]\n",
      " 96%|██████████████████████████████████████████████████████████████████▍  | 4259840/4422102 [01:59<00:04, 39054.94it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████▌  | 4268032/4422102 [01:59<00:05, 30710.93it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████▋  | 4276224/4422102 [02:00<00:05, 26966.56it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████▊  | 4284416/4422102 [02:00<00:05, 24759.81it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████▉  | 4292608/4422102 [02:01<00:07, 17596.15it/s]\n",
      " 97%|███████████████████████████████████████████████████████████████████  | 4300800/4422102 [02:01<00:06, 17961.61it/s]\n",
      " 97%|███████████████████████████████████████████████████████████████████▏ | 4308992/4422102 [02:02<00:06, 18786.51it/s]\n",
      " 98%|███████████████████████████████████████████████████████████████████▎ | 4317184/4422102 [02:02<00:06, 16957.58it/s]\n",
      " 98%|███████████████████████████████████████████████████████████████████▍ | 4325376/4422102 [02:03<00:07, 12958.41it/s]\n",
      " 98%|███████████████████████████████████████████████████████████████████▌ | 4333568/4422102 [02:04<00:06, 14612.01it/s]\n",
      " 98%|███████████████████████████████████████████████████████████████████▋ | 4341760/4422102 [02:04<00:05, 14364.48it/s]\n",
      " 98%|███████████████████████████████████████████████████████████████████▊ | 4349952/4422102 [02:05<00:04, 15867.76it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████ | 4358144/4422102 [02:05<00:03, 17109.79it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████▏| 4366336/4422102 [02:05<00:02, 20903.20it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████▎| 4374528/4422102 [02:06<00:02, 18198.57it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████▌| 4390912/4422102 [02:06<00:01, 20291.14it/s]\n",
      " 99%|████████████████████████████████████████████████████████████████████▋| 4399104/4422102 [02:07<00:01, 20463.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████▊| 4407296/4422102 [02:07<00:00, 20407.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████▉| 4415488/4422102 [02:09<00:00, 11684.69it/s]\n",
      "4423680it [02:09, 13459.58it/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                                                         | 0/5148 [00:00<?, ?it/s]\n",
      "\n",
      "8192it [00:00, 10451.76it/s]                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "mean, std = 0.28604059698879553, 0.35302424451492237\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = FashionMNIST('./data/FashionMNIST', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "                             ]))\n",
    "test_dataset = FashionMNIST('./data/FashionMNIST', train=False, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((mean,), (std,))\n",
    "                            ]))\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcZTFRnjCut3"
   },
   "source": [
    "## Common setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Dz2xh66UCut5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fashion_mnist_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                         'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22', '#17becf']\n",
    "mnist_classes = fashion_mnist_classes\n",
    "\n",
    "def plot_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(10):\n",
    "        inds = np.where(targets==i)[0]\n",
    "        plt.scatter(embeddings[inds,0], embeddings[inds,1], alpha=0.5, color=colors[i])\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    plt.legend(mnist_classes)\n",
    "\n",
    "def extract_embeddings(dataloader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), 2))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxkRm-RO7Bji"
   },
   "source": [
    "# Baseline: Classification with softmax\n",
    "We'll train the model for classification and use outputs of penultimate layer as embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "y29hMdwo7Bjl"
   },
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "batch_size = 256\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet, ClassificationNet\n",
    "from metrics import AccumulatedAccuracyMetric\n",
    "\n",
    "embedding_net = EmbeddingNet()\n",
    "model = ClassificationNet(embedding_net, n_classes=n_classes)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2397
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 438517,
     "status": "ok",
     "timestamp": 1528588135301,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "J5ntvNU77Bjo",
    "outputId": "bf6814a5-8cce-45c4-df08-0cb764dafefe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/60000 (0%)]\tLoss: 2.359652\tAccuracy: 12.109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4423680it [02:24, 13459.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [12800/60000 (21%)]\tLoss: 3.029367\tAccuracy: 23.291973039215687\n",
      "Train: [25600/60000 (43%)]\tLoss: 1.384446\tAccuracy: 31.841738861386137\n",
      "Train: [38400/60000 (64%)]\tLoss: 1.133904\tAccuracy: 41.121688741721854\n",
      "Train: [51200/60000 (85%)]\tLoss: 0.997161\tAccuracy: 47.471626243781095\n",
      "Epoch: 1/20. Train set: Average loss: 1.5361\tAccuracy: 50.696666666666665\n",
      "Epoch: 1/20. Validation set: Average loss: 0.8460\tAccuracy: 72.76\n",
      "Train: [0/60000 (0%)]\tLoss: 0.799006\tAccuracy: 73.828125\n",
      "Train: [12800/60000 (21%)]\tLoss: 0.799695\tAccuracy: 74.04258578431373\n",
      "Train: [25600/60000 (43%)]\tLoss: 0.718455\tAccuracy: 74.94585396039604\n",
      "Train: [38400/60000 (64%)]\tLoss: 0.674215\tAccuracy: 75.5898178807947\n",
      "Train: [51200/60000 (85%)]\tLoss: 0.625263\tAccuracy: 76.14466728855722\n",
      "Epoch: 2/20. Train set: Average loss: 0.6878\tAccuracy: 76.49666666666667\n",
      "Epoch: 2/20. Validation set: Average loss: 0.5897\tAccuracy: 78.62\n",
      "Train: [0/60000 (0%)]\tLoss: 0.521450\tAccuracy: 80.46875\n",
      "Train: [12800/60000 (21%)]\tLoss: 0.564510\tAccuracy: 79.78707107843137\n",
      "Train: [25600/60000 (43%)]\tLoss: 0.549715\tAccuracy: 79.90408415841584\n",
      "Train: [38400/60000 (64%)]\tLoss: 0.496431\tAccuracy: 80.859375\n",
      "Train: [51200/60000 (85%)]\tLoss: 0.495895\tAccuracy: 81.47154850746269\n",
      "Epoch: 3/20. Train set: Average loss: 0.5211\tAccuracy: 81.74166666666666\n",
      "Epoch: 3/20. Validation set: Average loss: 0.4927\tAccuracy: 83.61\n",
      "Train: [0/60000 (0%)]\tLoss: 0.451542\tAccuracy: 84.765625\n",
      "Train: [12800/60000 (21%)]\tLoss: 0.443553\tAccuracy: 84.5281862745098\n",
      "Train: [25600/60000 (43%)]\tLoss: 0.458519\tAccuracy: 84.46395420792079\n",
      "Train: [38400/60000 (64%)]\tLoss: 0.447725\tAccuracy: 84.47847682119205\n",
      "Train: [51200/60000 (85%)]\tLoss: 0.426370\tAccuracy: 84.66068097014926\n",
      "Epoch: 4/20. Train set: Average loss: 0.4438\tAccuracy: 84.805\n",
      "Epoch: 4/20. Validation set: Average loss: 0.4835\tAccuracy: 84.03\n",
      "Train: [0/60000 (0%)]\tLoss: 0.433632\tAccuracy: 83.203125\n",
      "Train: [12800/60000 (21%)]\tLoss: 0.402446\tAccuracy: 86.02941176470588\n",
      "Train: [25600/60000 (43%)]\tLoss: 0.401878\tAccuracy: 86.06512995049505\n",
      "Train: [38400/60000 (64%)]\tLoss: 0.389954\tAccuracy: 86.27897350993378\n"
     ]
    }
   ],
   "source": [
    "fit(train_loader, test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AccumulatedAccuracyMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23634,
     "status": "ok",
     "timestamp": 1528588158972,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "REAGu3f-7Bjt",
    "outputId": "7b20e0c5-cb5b-4b38-ddb1-78692c9c7852"
   },
   "outputs": [],
   "source": [
    "train_embeddings_baseline, train_labels_baseline = extract_embeddings(train_loader, model)\n",
    "plot_embeddings(train_embeddings_baseline, train_labels_baseline)\n",
    "val_embeddings_baseline, val_labels_baseline = extract_embeddings(test_loader, model)\n",
    "plot_embeddings(val_embeddings_baseline, val_labels_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9FhHE-tCuuc"
   },
   "source": [
    "# Siamese network\n",
    "We'll train a siamese network that takes a pair of images and trains the embeddings so that the distance between them is minimized if their from the same class or greater than some margin value if they represent different classes.\n",
    "We'll minimize a contrastive loss function*:\n",
    "$$L_{contrastive}(x_0, x_1, y) = \\frac{1}{2} y \\lVert f(x_0)-f(x_1)\\rVert_2^2 + \\frac{1}{2}(1-y)\\{max(0, m-\\lVert f(x_0)-f(x_1)\\rVert_2)\\}^2$$\n",
    "\n",
    "*Raia Hadsell, Sumit Chopra, Yann LeCun, [Dimensionality reduction by learning an invariant mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf), CVPR 2006*\n",
    "\n",
    "## Steps\n",
    "1. Create a dataset returning pairs - **SiameseMNIST** class from *datasets.py*, wrapper for MNIST-like classes.\n",
    "2. Define **embedding** *(mapping)* network $f(x)$ - **EmbeddingNet** from *networks.py*\n",
    "3. Define **siamese** network processing pairs of inputs - **SiameseNet** wrapping *EmbeddingNet*\n",
    "4. Train the network with **ContrastiveLoss** - *losses.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-qpIq-TzCuue"
   },
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import SiameseMNIST\n",
    "\n",
    "# Step 1\n",
    "siamese_train_dataset = SiameseMNIST(train_dataset) # Returns pairs of images and target same/different\n",
    "siamese_test_dataset = SiameseMNIST(test_dataset)\n",
    "batch_size = 128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet, SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "\n",
    "# Step 2\n",
    "embedding_net = EmbeddingNet()\n",
    "# Step 3\n",
    "model = SiameseNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Step 4\n",
    "margin = 1.\n",
    "loss_fn = ContrastiveLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 930771,
     "status": "ok",
     "timestamp": 1528589092774,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "_IqiBATeCuuh",
    "outputId": "8110dc3e-337c-417b-8e88-ac0ceaa3337b"
   },
   "outputs": [],
   "source": [
    "fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22170,
     "status": "ok",
     "timestamp": 1528589115036,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "rBBBuPjiCuup",
    "outputId": "6f426277-9dda-48e6-9eef-e4c54349d33a"
   },
   "outputs": [],
   "source": [
    "train_embeddings_cl, train_labels_cl = extract_embeddings(train_loader, model)\n",
    "plot_embeddings(train_embeddings_cl, train_labels_cl)\n",
    "val_embeddings_cl, val_labels_cl = extract_embeddings(test_loader, model)\n",
    "plot_embeddings(val_embeddings_cl, val_labels_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbKXy6yQCuuu"
   },
   "source": [
    "# Triplet network\n",
    "We'll train a triplet network, that takes an anchor, positive (same class as anchor) and negative (different class than anchor) examples. The objective is to learn embeddings such that the anchor is closer to the positive example than it is to the negative example by some margin value.\n",
    "\n",
    "![alt text](images/anchor_negative_positive.png \"Source: FaceNet\")\n",
    "Source: [2] *Schroff, Florian, Dmitry Kalenichenko, and James Philbin. [Facenet: A unified embedding for face recognition and clustering.](https://arxiv.org/abs/1503.03832) CVPR 2015.*\n",
    "\n",
    "**Triplet loss**:   $L_{triplet}(x_a, x_p, x_n) = max(0, m +  \\lVert f(x_a)-f(x_p)\\rVert_2^2 - \\lVert f(x_a)-f(x_n)\\rVert_2^2$\\)\n",
    "\n",
    "## Steps\n",
    "1. Create a dataset returning triplets - **TripletMNIST** class from *datasets.py*, wrapper for MNIST-like classes\n",
    "2. Define **embedding** *(mapping)* network $f(x)$ - **EmbeddingNet** from *networks.py*\n",
    "3. Define **triplet** network processing triplets - **TripletNet** wrapping *EmbeddingNet*\n",
    "4. Train the network with **TripletLoss** - *losses.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jv4DvFucCuuu"
   },
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import TripletMNIST\n",
    "\n",
    "triplet_train_dataset = TripletMNIST(train_dataset) # Returns triplets of images\n",
    "triplet_test_dataset = TripletMNIST(test_dataset)\n",
    "batch_size = 128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet, TripletNet\n",
    "from losses import TripletLoss\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EmbeddingNet()\n",
    "model = TripletNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1305892,
     "status": "ok",
     "timestamp": 1528590422778,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "Dj9AoYpsCuuz",
    "outputId": "4f81c75f-1d16-4c9c-e05c-b26d5f39fa84"
   },
   "outputs": [],
   "source": [
    "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22976,
     "status": "ok",
     "timestamp": 1528590445794,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "ysh4Ry7ZCuu_",
    "outputId": "2ea247e2-eb96-405a-aa5a-b3c0b565d2fd"
   },
   "outputs": [],
   "source": [
    "train_embeddings_tl, train_labels_tl = extract_embeddings(train_loader, model)\n",
    "plot_embeddings(train_embeddings_tl, train_labels_tl)\n",
    "val_embeddings_tl, val_labels_tl = extract_embeddings(test_loader, model)\n",
    "plot_embeddings(val_embeddings_tl, val_labels_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7C9H1_nCuvJ"
   },
   "source": [
    "# Online pair/triplet selection - negative mining\n",
    "There are couple of problems with siamese and triplet networks.\n",
    "1. The number of possible pairs/triplets grows **quadratically/cubically** with the number of examples. It's infeasible to process them all\n",
    "2. We generate pairs/triplets randomly. As the training continues, more and more pairs/triplets are easy to deal with (their loss value is very small or even 0), preventing the network from training. We need to provide the network with **hard examples**.\n",
    "3. Each image that is fed to the network is used only for computation of contrastive/triplet loss for only one pair/triplet. The computation is somewhat wasted; once the embedding is computed, it could be reused for many pairs/triplets.\n",
    "\n",
    "To deal with that efficiently, we'll feed a network with standard mini-batches as we did for classification. The loss function will be responsible for selection of hard pairs and triplets within mini-batch. In these case, if we feed the network with 16 images per 10 classes, we can process up to $159*160/2 = 12720$ pairs and $10*16*15/2*(9*16) = 172800$ triplets, compared to 80 pairs and 53 triplets in previous implementation.\n",
    "\n",
    "We can find some strategies on how to select triplets in [2] and [3] *Alexander Hermans, Lucas Beyer, Bastian Leibe, [In Defense of the Triplet Loss for Person Re-Identification](https://arxiv.org/pdf/1703.07737), 2017*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k806qej9CuvL"
   },
   "source": [
    "## Online pair selection\n",
    "## Steps\n",
    "1. Create **BalancedBatchSampler** - samples $N$ classes and $M$ samples *datasets.py*\n",
    "2. Create data loaders with the batch sampler\n",
    "3. Define **embedding** *(mapping)* network $f(x)$ - **EmbeddingNet** from *networks.py*\n",
    "4. Define a **PairSelector** that takes embeddings and original labels and returns valid pairs within a minibatch\n",
    "5. Define **OnlineContrastiveLoss** that will use a *PairSelector* and compute *ContrastiveLoss* on such pairs\n",
    "6. Train the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "goVi1_-PCuvL"
   },
   "outputs": [],
   "source": [
    "from datasets import BalancedBatchSampler\n",
    "\n",
    "# We'll create mini batches by sampling labels that will be present in the mini batch and number of examples from each class\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset.train_labels, n_classes=10, n_samples=25)\n",
    "test_batch_sampler = BalancedBatchSampler(test_dataset.test_labels, n_classes=10, n_samples=25)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_test_loader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_batch_sampler, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet\n",
    "from losses import OnlineContrastiveLoss\n",
    "from utils import AllPositivePairSelector, HardNegativePairSelector # Strategies for selecting pairs within a minibatch\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EmbeddingNet()\n",
    "model = embedding_net\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = OnlineContrastiveLoss(margin, HardNegativePairSelector())\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567133,
     "status": "ok",
     "timestamp": 1528591015945,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "SacMTqN6CuvO",
    "outputId": "87a2c414-a641-4cde-ac89-96e7c10cef02"
   },
   "outputs": [],
   "source": [
    "all_embeddings = fit(online_train_loader, online_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15155,
     "status": "ok",
     "timestamp": 1528591031137,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "ZCvF0AlCCuvX",
    "outputId": "27de240c-eb68-4de0-b57b-f386ccb23ebb"
   },
   "outputs": [],
   "source": [
    "train_embeddings_ocl, train_labels_ocl = extract_embeddings(train_loader, model)\n",
    "plot_embeddings(train_embeddings_ocl, train_labels_ocl)\n",
    "val_embeddings_ocl, val_labels_ocl = extract_embeddings(test_loader, model)\n",
    "plot_embeddings(val_embeddings_ocl, val_labels_ocl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgIGiMwICuvn"
   },
   "source": [
    "## Online triplet selection\n",
    "## Steps\n",
    "1. Create **BalancedBatchSampler** - samples $N$ classes and $M$ samples *datasets.py*\n",
    "2. Create data loaders with the batch sampler\n",
    "3. Define **embedding** *(mapping)* network $f(x)$ - **EmbeddingNet** from *networks.py*\n",
    "4. Define a **TripletSelector** that takes embeddings and original labels and returns valid triplets within a minibatch\n",
    "5. Define **OnlineTripletLoss** that will use a *TripletSelector* and compute *TripletLoss* on such pairs\n",
    "6. Train the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JzpYzMUuCuvp"
   },
   "outputs": [],
   "source": [
    "from datasets import BalancedBatchSampler\n",
    "\n",
    "# We'll create mini batches by sampling labels that will be present in the mini batch and number of examples from each class\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset.train_labels, n_classes=10, n_samples=25)\n",
    "test_batch_sampler = BalancedBatchSampler(test_dataset.test_labels, n_classes=10, n_samples=25)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_test_loader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_batch_sampler, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet\n",
    "from losses import OnlineTripletLoss\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EmbeddingNet()\n",
    "model = embedding_net\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = OnlineTripletLoss(margin, RandomNegativeTripletSelector(margin))\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2163515,
     "status": "ok",
     "timestamp": 1528593197388,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "W-bDxqVJCuvs",
    "outputId": "1ef0d7ce-6c6a-4dc0-e879-348e081f1bd3"
   },
   "outputs": [],
   "source": [
    "fit(online_train_loader, online_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15139,
     "status": "ok",
     "timestamp": 1528593212580,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "dNrbA2hCCuvw",
    "outputId": "e2b0d141-2b88-459a-af17-f4433b5564b9"
   },
   "outputs": [],
   "source": [
    "train_embeddings_otl, train_labels_otl = extract_embeddings(train_loader, model)\n",
    "plot_embeddings(train_embeddings_otl, train_labels_otl)\n",
    "val_embeddings_otl, val_labels_otl = extract_embeddings(test_loader, model)\n",
    "plot_embeddings(val_embeddings_otl, val_labels_otl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3897,
     "status": "ok",
     "timestamp": 1528593217032,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "aDeV-K4o7Bk2",
    "outputId": "a4c8c20b-8d41-4c4d-d1a0-4258a4fa5b30"
   },
   "outputs": [],
   "source": [
    "display_emb_online, display_emb, display_label_online, display_label = train_embeddings_ocl, train_embeddings_cl, train_labels_ocl, train_labels_cl\n",
    "# display_emb_online, display_emb, display_label_online, display_label = val_embeddings_ocl, val_embeddings_cl, val_labels_ocl, val_labels_cl\n",
    "\n",
    "x_lim = (np.min(display_emb_online[:,0]), np.max(display_emb_online[:,0]))\n",
    "y_lim = (np.min(display_emb_online[:,1]), np.max(display_emb_online[:,1]))\n",
    "x_lim = (min(x_lim[0], np.min(display_emb[:,0])), max(x_lim[1], np.max(display_emb[:,0])))\n",
    "y_lim = (min(y_lim[0], np.min(display_emb[:,1])), max(y_lim[1], np.max(display_emb[:,1])))\n",
    "\n",
    "plot_embeddings(display_emb, display_label, x_lim, y_lim)\n",
    "plot_embeddings(display_emb_online, display_label_online, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3858,
     "status": "ok",
     "timestamp": 1528593220933,
     "user": {
      "displayName": "Adam Bielski",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113360808941199578430"
     },
     "user_tz": -120
    },
    "id": "tNY7NReM0zsq",
    "outputId": "eede3036-9fa4-4e78-c7bc-e53f991074b1"
   },
   "outputs": [],
   "source": [
    "display_emb_online, display_emb, display_label_online, display_label = train_embeddings_otl, train_embeddings_tl, train_labels_otl, train_labels_tl\n",
    "# display_emb_online, display_emb, display_label_online, display_label = val_embeddings_otl, val_embeddings_tl, val_labels_otl, val_labels_tl\n",
    "x_lim = (np.min(display_emb_online[:,0]), np.max(display_emb_online[:,0]))\n",
    "y_lim = (np.min(display_emb_online[:,1]), np.max(display_emb_online[:,1]))\n",
    "x_lim = (min(x_lim[0], np.min(display_emb[:,0])), max(x_lim[1], np.max(display_emb[:,0])))\n",
    "y_lim = (min(y_lim[0], np.min(display_emb[:,1])), max(y_lim[1], np.max(display_emb[:,1])))\n",
    "plot_embeddings(display_emb, display_label, x_lim, y_lim)\n",
    "plot_embeddings(display_emb_online, display_label_online, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9AOfKw7W7VwT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Experiments_FashionMNIST.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
